---
Title: Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control
Date: 2018-02-06 10:20
Modified: Wed, 07. Feb 2018 02:06PM 
Category: Publication
Tags: RL, DeepLearning, ContinualLearning
Author: Glen Berseth
Cover: <img width="100%" src="/projects/PLAiD/PLAiD_teaser.png">
Authors: Glen Berseth, Cheng Xie, Paul Cernek, Michiel van de Panne
Summary: Deep reinforcement learning has demonstrated increasing capabilities for continuous control problems, including agents that can move with skill and agility through their environment. An open problem in this setting is that of developing good strategies for integrating or merging policies for multiple skills, where each individual skill is a specialist in a specific skill and its associated state distribution. We extend policy distillation methods to the continuous action setting and leverage this technique to combine expert policies, as evaluated in the domain of simulated bipedal locomotion across different classes of terrain. We also introduce an input injection method for augmenting an existing policy network to exploit new input features. Lastly, our method uses transfer learning to assist in the efficient acquisition of new skills. The combination of these methods allows a policy to be incrementally augmented with new skills. We compare our progressive learning and integration via distillation (PLAID) method against three alternative baselines.
comments: true
Type: Life Long Learning
TitleShort: Sequential task learning 
---


<div align="center">
	<p>
			*Glen Berseth and *Cheng Xie and Paul Cernek and Michiel van de Panne
	</p>
	<p>	
            University of British Columbia
    </p>
    <p>	
            * Equal Contribution
    </p>
    
</div>

<div align="center">
			<span class="STYLE17"> <img width="800" src="/projects/PLAiD/PLAiD_teaser.png"> </span> &nbsp; &nbsp; &nbsp;

</div>

# Abstract

Deep reinforcement learning has demonstrated increasing capabilities for continuous control problems,
including agents that can move with skill and agility through their environment. 
An open problem in this setting is that of developing good strategies for integrating or merging policies
for multiple skills, where each individual skill is a specialist in a specific skill and its associated state distribution. 
We extend policy distillation methods to the continuous action setting and leverage this technique to combine expert policies,
as evaluated in the domain of simulated bipedal locomotion across different classes of terrain.
We also introduce an input injection method for augmenting an existing policy network to exploit new input features.
Lastly, our method uses transfer learning to assist in the efficient acquisition of new skills.
The combination of these methods allows a policy to be incrementally augmented with new skills.
We compare our progressive learning and integration via distillation (PLAID) method
against three alternative baselines.


## Files

[Paper](/projects/PLAiD/paper.pdf)
[Learning code](https://github.com/FracturedPlane/RL-Framework/releases/tag/0.2)
[Simulation Environment](https://github.com/UBCMOCCA/TerrainRL/releases/tag/0.2.3)

## Videos!

<iframe width="560" height="315" src="https://www.youtube.com/embed/_DjHbHCXGk0" frameborder="0" ></iframe>

### Bibtex

```
@article{2018-ICLR-PLAiD,
  title={Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control},
  author={Glen Berseth and Cheng Xie and Paul Cernek and Michiel van de Panne},
  journal = {International Conference on Learning Representations},
  year={2018}
}
```

### Acknowledgements

We thank the anonymous reviewers for their helpful feedback. This research was funded in part by an NSERC Discovery Grant (RGPIN-2015-04843).

